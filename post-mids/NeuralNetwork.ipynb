{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZBkE_OVUc7K",
        "outputId": "586db6f6-d7bc-47f9-dbf5-bf4538988090"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Adithya Sunilkumar - IMT2021068\n",
        "# Kevin Adesara - IMT2021070\n",
        "# Anant Ojha - IMT2021102\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXnBOZV6l1yj",
        "outputId": "4dbb0323-208a-485b-be02-52c615a5e4e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Check if TensorFlow is using the GPU\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    print('GPU device not found')\n",
        "else:\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "\n",
        "# Load data\n",
        "train_data = pd.read_csv('/content/drive/MyDrive/data/train.csv')\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/data/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pk1Y_yWEUv1F"
      },
      "outputs": [],
      "source": [
        "#Feature engineering, same as assignment 1\n",
        "train_frequency = train_data['patient_id'].value_counts().to_dict()\n",
        "test_frequency = test_data['patient_id'].value_counts().to_dict()\n",
        "frequency = {}\n",
        "\n",
        "for i in train_frequency:\n",
        "    frequency[i] = 0\n",
        "for i in test_frequency:\n",
        "    frequency[i] = 0\n",
        "\n",
        "for i in train_frequency:\n",
        "    frequency[i] += train_frequency[i]\n",
        "for i in test_frequency:\n",
        "    frequency[i] += test_frequency[i]\n",
        "\n",
        "train_data['frequency'] = train_data['patient_id'].map(frequency)\n",
        "test_data['frequency'] = test_data['patient_id'].map(frequency)\n",
        "\n",
        "# Assuming 'patient_id' and 'enc_id' are not features for training\n",
        "features = train_data.drop(['patient_id', 'enc_id', 'readmission_id'], axis=1)\n",
        "labels = to_categorical(train_data['readmission_id'])  # One-hot encoding the labels\n",
        "\n",
        "# Handling missing values and encoding categorical variables\n",
        "numeric_features = features.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = features.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Create a column transformer for preprocessing\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', SimpleImputer(strategy='mean'), numeric_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)])\n",
        "\n",
        "# Splitting the training data for training and validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply the preprocessing\n",
        "X_train = preprocessor.fit_transform(X_train)\n",
        "X_val = preprocessor.transform(X_val)\n",
        "test_data_processed = preprocessor.transform(test_data.drop(['patient_id', 'enc_id'], axis=1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7u66dl3bU_zS"
      },
      "outputs": [],
      "source": [
        "# 0.2 droupout rate, RELU, 0.001 learning rate, 0.722 accuracy\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')  # Output layer for 3 classes\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6r_pvefQa5_s"
      },
      "outputs": [],
      "source": [
        "# 0.5 droupout rate, RELU, 0.001 learning rate, 0.719\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')  # Output layer for 3 classes\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4L-UEvkZyaF"
      },
      "outputs": [],
      "source": [
        "# 0.2 droupout rate, sigmoid, 0.001 learning rate, 0.720\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='sigmoid', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(64, activation='sigmoid'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')  # Output layer for 3 classes\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXTDjJK3am9-"
      },
      "outputs": [],
      "source": [
        "# 0.2 droupout rate, RELU, 0.01 learning rate, 0.712\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')  # Output layer for 3 classes\n",
        "])\n",
        "\n",
        "custom_optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "model.compile(optimizer=custom_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ROc-403VEEg",
        "outputId": "125bde31-de6f-4b76-d352-2c3d7b8f3a57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1781/1781 [==============================] - 15s 7ms/step - loss: 0.8163 - accuracy: 0.6435 - val_loss: 0.7545 - val_accuracy: 0.6915\n",
            "Epoch 2/10\n",
            "1781/1781 [==============================] - 11s 6ms/step - loss: 0.7552 - accuracy: 0.6789 - val_loss: 0.7441 - val_accuracy: 0.6966\n",
            "Epoch 3/10\n",
            "1781/1781 [==============================] - 9s 5ms/step - loss: 0.7486 - accuracy: 0.6743 - val_loss: 0.7381 - val_accuracy: 0.6988\n",
            "Epoch 4/10\n",
            "1781/1781 [==============================] - 10s 6ms/step - loss: 0.7441 - accuracy: 0.6867 - val_loss: 0.7665 - val_accuracy: 0.6598\n",
            "Epoch 5/10\n",
            "1781/1781 [==============================] - 10s 6ms/step - loss: 0.7343 - accuracy: 0.6947 - val_loss: 0.7335 - val_accuracy: 0.6946\n",
            "Epoch 6/10\n",
            "1781/1781 [==============================] - 9s 5ms/step - loss: 0.7284 - accuracy: 0.7015 - val_loss: 0.7267 - val_accuracy: 0.7088\n",
            "Epoch 7/10\n",
            "1781/1781 [==============================] - 9s 5ms/step - loss: 0.7208 - accuracy: 0.7073 - val_loss: 0.7287 - val_accuracy: 0.7095\n",
            "Epoch 8/10\n",
            "1781/1781 [==============================] - 10s 5ms/step - loss: 0.7157 - accuracy: 0.7120 - val_loss: 0.7363 - val_accuracy: 0.7070\n",
            "Epoch 9/10\n",
            "1781/1781 [==============================] - 9s 5ms/step - loss: 0.7166 - accuracy: 0.7110 - val_loss: 0.7218 - val_accuracy: 0.7127\n",
            "Epoch 10/10\n",
            "1781/1781 [==============================] - 9s 5ms/step - loss: 0.7156 - accuracy: 0.7125 - val_loss: 0.7346 - val_accuracy: 0.7017\n"
          ]
        }
      ],
      "source": [
        "# Training the model (10 epochs, 32 batch size)\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkZeM1uisYny",
        "outputId": "504f106a-1634-4c55-a533-94c805791f4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "891/891 [==============================] - 15s 12ms/step - loss: 0.8449 - accuracy: 0.6267 - val_loss: 0.7540 - val_accuracy: 0.6764\n",
            "Epoch 2/20\n",
            "891/891 [==============================] - 7s 8ms/step - loss: 0.7539 - accuracy: 0.6831 - val_loss: 0.7293 - val_accuracy: 0.7012\n",
            "Epoch 3/20\n",
            "891/891 [==============================] - 5s 6ms/step - loss: 0.7333 - accuracy: 0.6956 - val_loss: 0.7246 - val_accuracy: 0.7077\n",
            "Epoch 4/20\n",
            "891/891 [==============================] - 8s 8ms/step - loss: 0.7245 - accuracy: 0.7008 - val_loss: 0.7193 - val_accuracy: 0.7107\n",
            "Epoch 5/20\n",
            "891/891 [==============================] - 5s 6ms/step - loss: 0.7167 - accuracy: 0.7056 - val_loss: 0.7224 - val_accuracy: 0.7088\n",
            "Epoch 6/20\n",
            "891/891 [==============================] - 5s 6ms/step - loss: 0.7081 - accuracy: 0.7123 - val_loss: 0.7286 - val_accuracy: 0.7007\n",
            "Epoch 7/20\n",
            "891/891 [==============================] - 5s 6ms/step - loss: 0.7089 - accuracy: 0.7113 - val_loss: 0.7127 - val_accuracy: 0.7127\n",
            "Epoch 8/20\n",
            "891/891 [==============================] - 6s 7ms/step - loss: 0.7021 - accuracy: 0.7141 - val_loss: 0.7122 - val_accuracy: 0.7118\n",
            "Epoch 9/20\n",
            "891/891 [==============================] - 5s 6ms/step - loss: 0.6996 - accuracy: 0.7160 - val_loss: 0.7096 - val_accuracy: 0.7118\n",
            "Epoch 10/20\n",
            "891/891 [==============================] - 6s 7ms/step - loss: 0.6992 - accuracy: 0.7157 - val_loss: 0.7061 - val_accuracy: 0.7125\n",
            "Epoch 11/20\n",
            "891/891 [==============================] - 5s 5ms/step - loss: 0.6928 - accuracy: 0.7196 - val_loss: 0.7058 - val_accuracy: 0.7149\n",
            "Epoch 12/20\n",
            "891/891 [==============================] - 9s 10ms/step - loss: 0.6931 - accuracy: 0.7180 - val_loss: 0.7064 - val_accuracy: 0.7121\n",
            "Epoch 13/20\n",
            "891/891 [==============================] - 5s 5ms/step - loss: 0.6899 - accuracy: 0.7198 - val_loss: 0.7127 - val_accuracy: 0.7106\n",
            "Epoch 14/20\n",
            "891/891 [==============================] - 6s 7ms/step - loss: 0.6892 - accuracy: 0.7196 - val_loss: 0.7141 - val_accuracy: 0.7127\n",
            "Epoch 15/20\n",
            "891/891 [==============================] - 5s 6ms/step - loss: 0.6868 - accuracy: 0.7220 - val_loss: 0.7100 - val_accuracy: 0.7112\n",
            "Epoch 16/20\n",
            "891/891 [==============================] - 6s 7ms/step - loss: 0.6847 - accuracy: 0.7218 - val_loss: 0.7078 - val_accuracy: 0.7118\n",
            "Epoch 17/20\n",
            "891/891 [==============================] - 5s 6ms/step - loss: 0.6831 - accuracy: 0.7229 - val_loss: 0.7166 - val_accuracy: 0.7080\n",
            "Epoch 18/20\n",
            "891/891 [==============================] - 7s 7ms/step - loss: 0.6799 - accuracy: 0.7234 - val_loss: 0.7100 - val_accuracy: 0.7123\n",
            "Epoch 19/20\n",
            "891/891 [==============================] - 6s 7ms/step - loss: 0.6765 - accuracy: 0.7246 - val_loss: 0.7111 - val_accuracy: 0.7125\n",
            "Epoch 20/20\n",
            "891/891 [==============================] - 8s 8ms/step - loss: 0.6779 - accuracy: 0.7245 - val_loss: 0.7125 - val_accuracy: 0.7123\n"
          ]
        }
      ],
      "source": [
        "# Fine tuned parameters, 6 layers, 64 batch size, 20 epochs, 0.723 accuracy\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "custom_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "model.compile(optimizer=custom_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fine-tuned parameters\n",
        "batch_size = 64\n",
        "epochs = 20\n",
        "\n",
        "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6XBHrzRVLl0",
        "outputId": "b92a1f0d-25b5-4a66-90ea-7cc215db4d92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "955/955 [==============================] - 2s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "# Making predictions\n",
        "predictions = model.predict(test_data_processed)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Saving to CSV\n",
        "output = pd.DataFrame({'enc_id': test_data['enc_id'], 'readmission_id': predicted_labels})\n",
        "output.to_csv('/content/drive/MyDrive/data/output.csv', index=False)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
