{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-21T12:38:32.604059Z",
          "iopub.status.busy": "2023-10-21T12:38:32.603327Z",
          "iopub.status.idle": "2023-10-21T12:38:33.911320Z",
          "shell.execute_reply": "2023-10-21T12:38:33.909828Z",
          "shell.execute_reply.started": "2023-10-21T12:38:32.604013Z"
        },
        "trusted": true,
        "id": "xHyulmD3Uqeb"
      },
      "outputs": [],
      "source": [
        "# Adithya Sunilkumar - IMT2021068\n",
        "# Kevin Adesara - IMT2021070\n",
        "# Anant Ojha - IMT2021102\n",
        "\n",
        "# All the imports and the input datasets\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8f8Qg3WU10L",
        "outputId": "7b6105c8-7dd7-4115-d67a-80bbb05a8f8f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data = pd.read_csv(\"/kaggle/input/hospital/train.csv\")\n",
        "# test_data = pd.read_csv(\"/kaggle/input/hospital/test.csv\")\n",
        "\n",
        "train_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/train.csv')\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/test.csv')\n",
        "\n",
        "backup_train = train_data\n",
        "backup_test = test_data"
      ],
      "metadata": {
        "id": "Ah5m3jY9VCXL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-21T12:38:40.989990Z",
          "iopub.status.busy": "2023-10-21T12:38:40.989509Z",
          "iopub.status.idle": "2023-10-21T12:38:41.305651Z",
          "shell.execute_reply": "2023-10-21T12:38:41.304161Z",
          "shell.execute_reply.started": "2023-10-21T12:38:40.989951Z"
        },
        "trusted": true,
        "id": "3MPLeOmLUqee"
      },
      "outputs": [],
      "source": [
        "# Feature Engineering\n",
        "\n",
        "train_frequency = train_data['patient_id'].value_counts().to_dict()\n",
        "test_frequency = test_data['patient_id'].value_counts().to_dict()\n",
        "frequency = {}\n",
        "\n",
        "for i in train_frequency:\n",
        "    frequency[i] = 0\n",
        "for i in test_frequency:\n",
        "    frequency[i] = 0\n",
        "\n",
        "for i in train_frequency:\n",
        "    frequency[i] += train_frequency[i]\n",
        "for i in test_frequency:\n",
        "    frequency[i] += test_frequency[i]\n",
        "\n",
        "train_data['frequency'] = train_data['patient_id'].map(frequency)\n",
        "test_data['frequency'] = test_data['patient_id'].map(frequency)\n",
        "\n",
        "drugs = ['metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone', 'tolazamide', 'examide', 'citoglipton', 'glyburide-metformin', 'glipizide-metformin', 'glimepiride-pioglitazone', 'metformin-rosiglitazone', 'metformin-pioglitazone', 'insulin']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMPkTAgBUqef"
      },
      "outputs": [],
      "source": [
        "# Only run this cell if you want to find frequencies of drugs. (Doesn't really help accuracy)\n",
        "\n",
        "for category in ['Up', 'Down', 'Steady']:\n",
        "    train_data[category.lower()] = train_data[drugs].eq(category).sum(axis=1)\n",
        "for category in ['Up', 'Down', 'Steady']:\n",
        "    test_data[category.lower()] = test_data[drugs].eq(category).sum(axis=1)\n",
        "train_data.to_csv('modified.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-21T12:38:46.851302Z",
          "iopub.status.busy": "2023-10-21T12:38:46.850860Z",
          "iopub.status.idle": "2023-10-21T12:38:47.413330Z",
          "shell.execute_reply": "2023-10-21T12:38:47.411841Z",
          "shell.execute_reply.started": "2023-10-21T12:38:46.851270Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oO-agVYzUqeg",
        "outputId": "bf2289cc-a0d4-43e8-a6ef-bfc79abe9e87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial row count: 71236\n",
            "Row count after dropping: 71225\n"
          ]
        }
      ],
      "source": [
        "# Preprocessing, enter the list of categorical columns and the columns to be dropped here\n",
        "\n",
        "categorical_columns = ['race', 'age', 'gender', 'diabetesMed', 'change', 'diag_1', 'diag_2', 'diag_3']\n",
        "columns_to_drop = ['weight', 'medical_specialty', 'payer_code', 'max_glu_serum', 'A1Cresult']\n",
        "columns_to_drop.extend(drugs)\n",
        "\n",
        "for column in columns_to_drop:\n",
        "    if column in categorical_columns:\n",
        "        categorical_columns.remove(column)\n",
        "\n",
        "train_data = train_data.drop(columns=columns_to_drop, axis=1)\n",
        "print(\"Initial row count: \" + str(train_data.shape[0]))\n",
        "\n",
        "#Rows with more than 2 null values are dropped, rest are replaced with Mode\n",
        "train_data = train_data.dropna(thresh=train_data.shape[1]-2)\n",
        "print(\"Row count after dropping: \" + str(train_data.shape[0]))\n",
        "train_data = train_data.apply(lambda x: x.fillna(x.mode().iloc[0]))\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "for column in categorical_columns:\n",
        "    train_data[column] = label_encoder.fit_transform(train_data[column])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-21T10:16:05.227088Z",
          "iopub.status.busy": "2023-10-21T10:16:05.226561Z",
          "iopub.status.idle": "2023-10-21T10:22:07.126457Z",
          "shell.execute_reply": "2023-10-21T10:22:07.125058Z",
          "shell.execute_reply.started": "2023-10-21T10:16:05.227039Z"
        },
        "trusted": true,
        "id": "-do6cUbIUqeh"
      },
      "outputs": [],
      "source": [
        "# Model: Random Forest with Randomized Grid Search. Set n_iter to 10 for fine tuning but longer execution time. (Usually increases accuracy by 0.1%)\n",
        "\n",
        "X = train_data.drop(columns=['readmission_id'])\n",
        "y = train_data['readmission_id']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [3, 4, 5, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=5, cv=5, random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "best_params = random_search.best_params_\n",
        "print(\"Best Parameters:\", best_params)\n",
        "\n",
        "best_model = random_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-21T10:22:07.128311Z",
          "iopub.status.busy": "2023-10-21T10:22:07.127959Z",
          "iopub.status.idle": "2023-10-21T10:22:09.590372Z",
          "shell.execute_reply": "2023-10-21T10:22:09.589151Z",
          "shell.execute_reply.started": "2023-10-21T10:22:07.128281Z"
        },
        "trusted": true,
        "id": "oeWG1be-Uqeh"
      },
      "outputs": [],
      "source": [
        "# Output predicted values of test data and print accuracy\n",
        "\n",
        "test_x = test_data.drop(columns=columns_to_drop, axis=1)\n",
        "test_x = test_x.apply(lambda x: x.fillna(x.mode().iloc[0]))\n",
        "\n",
        "for column in categorical_columns:\n",
        "    test_x[column] = label_encoder.fit_transform(test_x[column])\n",
        "\n",
        "test_x = test_x[X.columns]\n",
        "test_predictions = best_model.predict(test_x)\n",
        "result_df = pd.DataFrame({'enc_id': test_data['enc_id'], 'predicted_readmission_id': test_predictions})\n",
        "\n",
        "result_df.to_csv('predicted_results.csv', index=False)\n",
        "\n",
        "val_predictions = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, val_predictions)\n",
        "print(f'Accuracy on the validation set: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-21T12:38:58.607465Z",
          "iopub.status.busy": "2023-10-21T12:38:58.606995Z",
          "iopub.status.idle": "2023-10-21T12:42:30.088129Z",
          "shell.execute_reply": "2023-10-21T12:42:30.086876Z",
          "shell.execute_reply.started": "2023-10-21T12:38:58.607429Z"
        },
        "trusted": true,
        "id": "Q5CZ5hPdUqei"
      },
      "outputs": [],
      "source": [
        "# Other tried models.\n",
        "# Model: XGBoost\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Define your features (X) and target (y)\n",
        "X = train_data.drop(columns=['readmission_id'])\n",
        "y = train_data['readmission_id']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create an XGBoost classifier with RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [3, 4, 5, None],\n",
        "    'min_child_weight': [1, 2, 4, 6],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "}\n",
        "\n",
        "xgb_classifier = XGBClassifier(random_state=42)  # Use XGBClassifier\n",
        "random_search = RandomizedSearchCV(xgb_classifier, param_distributions=param_dist, n_iter=5, cv=5, random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "best_params = random_search.best_params_\n",
        "print(\"Best Parameters:\", best_params)\n",
        "\n",
        "best_model = random_search.best_estimator_\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "\n",
        "# Generate a classification report to see precision, recall, F1-score, etc.\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-21T12:52:19.051040Z",
          "iopub.status.busy": "2023-10-21T12:52:19.050509Z",
          "iopub.status.idle": "2023-10-21T12:55:51.742690Z",
          "shell.execute_reply": "2023-10-21T12:55:51.741599Z",
          "shell.execute_reply.started": "2023-10-21T12:52:19.051003Z"
        },
        "trusted": true,
        "id": "AvV_nyaOUqei"
      },
      "outputs": [],
      "source": [
        "# Other tried models.\n",
        "# Model: AdaBoost\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "# Define your features (X) and target (y)\n",
        "X = train_data.drop(columns=['readmission_id'])\n",
        "y = train_data['readmission_id']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create an AdaBoost classifier with RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "}\n",
        "\n",
        "adaboost_classifier = AdaBoostClassifier(random_state=42)  # Use AdaBoostClassifier\n",
        "random_search = RandomizedSearchCV(adaboost_classifier, param_distributions=param_dist, n_iter=5, cv=5, random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "best_params = random_search.best_params_\n",
        "print(\"Best Parameters:\", best_params)\n",
        "\n",
        "best_model = random_search.best_estimator_\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "\n",
        "# Generate a classification report to see precision, recall, F1-score, etc.\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-21T13:18:05.944106Z",
          "iopub.status.busy": "2023-10-21T13:18:05.943521Z",
          "iopub.status.idle": "2023-10-21T13:25:05.983908Z",
          "shell.execute_reply": "2023-10-21T13:25:05.982358Z",
          "shell.execute_reply.started": "2023-10-21T13:18:05.944063Z"
        },
        "trusted": true,
        "id": "VUZ3Vi2mUqej"
      },
      "outputs": [],
      "source": [
        "# Other tried models.\n",
        "# Model: KNN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Define your features (X) and target (y)\n",
        "X = train_data.drop(columns=['readmission_id'])\n",
        "y = train_data['readmission_id']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a K-Nearest Neighbors (KNN) classifier with RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'n_neighbors': [3, 5, 7, 9],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'p': [1, 2]\n",
        "}\n",
        "\n",
        "knn_classifier = KNeighborsClassifier()  # Use KNN classifier\n",
        "random_search = RandomizedSearchCV(knn_classifier, param_distributions=param_dist, n_iter=5, cv=5, random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "best_params = random_search.best_params_\n",
        "print(\"Best Parameters:\", best_params)\n",
        "\n",
        "best_model = random_search.best_estimator_\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "\n",
        "# Generate a classification report to see precision, recall, F1-score, etc.\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXnzqVtOUvGP",
        "outputId": "cf86f530-d611-46be-a959-f1cdc18484c3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.2-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.3.post1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostClassifier\n",
        "\n",
        "# Define your features (X) and target (y)\n",
        "X = train_data.drop(columns=['readmission_id'])\n",
        "y = train_data['readmission_id']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a CatBoost classifier\n",
        "catboost_classifier = CatBoostClassifier(iterations=100, depth=6, learning_rate=0.1, loss_function='MultiClass', random_seed=42)\n",
        "\n",
        "# Train the CatBoost model on the training data\n",
        "catboost_classifier.fit(X_train, y_train, cat_features=categorical_columns)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = catboost_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "\n",
        "# Generate a classification report to see precision, recall, F1-score, etc.\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0el2QdRWEn6",
        "outputId": "c605f6f8-1902-4702-d599-f495b3df3619"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 1.0298302\ttotal: 845ms\tremaining: 1m 23s\n",
            "1:\tlearn: 0.9738634\ttotal: 1.51s\tremaining: 1m 13s\n",
            "2:\tlearn: 0.9298692\ttotal: 2.03s\tremaining: 1m 5s\n",
            "3:\tlearn: 0.8940318\ttotal: 2.45s\tremaining: 58.7s\n",
            "4:\tlearn: 0.8654168\ttotal: 2.82s\tremaining: 53.5s\n",
            "5:\tlearn: 0.8410671\ttotal: 3.05s\tremaining: 47.8s\n",
            "6:\tlearn: 0.8215152\ttotal: 3.31s\tremaining: 44s\n",
            "7:\tlearn: 0.8032477\ttotal: 3.56s\tremaining: 41s\n",
            "8:\tlearn: 0.7881926\ttotal: 3.82s\tremaining: 38.6s\n",
            "9:\tlearn: 0.7749015\ttotal: 4.04s\tremaining: 36.4s\n",
            "10:\tlearn: 0.7633676\ttotal: 4.29s\tremaining: 34.7s\n",
            "11:\tlearn: 0.7538011\ttotal: 4.55s\tremaining: 33.4s\n",
            "12:\tlearn: 0.7470725\ttotal: 4.73s\tremaining: 31.6s\n",
            "13:\tlearn: 0.7399942\ttotal: 4.98s\tremaining: 30.6s\n",
            "14:\tlearn: 0.7340450\ttotal: 5.25s\tremaining: 29.7s\n",
            "15:\tlearn: 0.7278544\ttotal: 5.44s\tremaining: 28.5s\n",
            "16:\tlearn: 0.7224710\ttotal: 5.58s\tremaining: 27.2s\n",
            "17:\tlearn: 0.7183840\ttotal: 5.71s\tremaining: 26s\n",
            "18:\tlearn: 0.7144555\ttotal: 5.84s\tremaining: 24.9s\n",
            "19:\tlearn: 0.7114834\ttotal: 5.97s\tremaining: 23.9s\n",
            "20:\tlearn: 0.7088707\ttotal: 6.11s\tremaining: 23s\n",
            "21:\tlearn: 0.7064110\ttotal: 6.24s\tremaining: 22.1s\n",
            "22:\tlearn: 0.7030952\ttotal: 6.38s\tremaining: 21.4s\n",
            "23:\tlearn: 0.7009087\ttotal: 6.52s\tremaining: 20.6s\n",
            "24:\tlearn: 0.6987798\ttotal: 6.65s\tremaining: 20s\n",
            "25:\tlearn: 0.6960813\ttotal: 6.79s\tremaining: 19.3s\n",
            "26:\tlearn: 0.6952861\ttotal: 6.92s\tremaining: 18.7s\n",
            "27:\tlearn: 0.6937308\ttotal: 7.05s\tremaining: 18.1s\n",
            "28:\tlearn: 0.6921167\ttotal: 7.18s\tremaining: 17.6s\n",
            "29:\tlearn: 0.6908611\ttotal: 7.33s\tremaining: 17.1s\n",
            "30:\tlearn: 0.6899451\ttotal: 7.46s\tremaining: 16.6s\n",
            "31:\tlearn: 0.6883702\ttotal: 7.59s\tremaining: 16.1s\n",
            "32:\tlearn: 0.6871252\ttotal: 7.73s\tremaining: 15.7s\n",
            "33:\tlearn: 0.6860010\ttotal: 7.86s\tremaining: 15.3s\n",
            "34:\tlearn: 0.6849080\ttotal: 8s\tremaining: 14.8s\n",
            "35:\tlearn: 0.6842595\ttotal: 8.12s\tremaining: 14.4s\n",
            "36:\tlearn: 0.6835590\ttotal: 8.26s\tremaining: 14.1s\n",
            "37:\tlearn: 0.6824312\ttotal: 8.4s\tremaining: 13.7s\n",
            "38:\tlearn: 0.6812400\ttotal: 8.53s\tremaining: 13.3s\n",
            "39:\tlearn: 0.6800435\ttotal: 8.66s\tremaining: 13s\n",
            "40:\tlearn: 0.6794666\ttotal: 8.8s\tremaining: 12.7s\n",
            "41:\tlearn: 0.6781092\ttotal: 8.93s\tremaining: 12.3s\n",
            "42:\tlearn: 0.6776669\ttotal: 9.07s\tremaining: 12s\n",
            "43:\tlearn: 0.6773463\ttotal: 9.19s\tremaining: 11.7s\n",
            "44:\tlearn: 0.6764470\ttotal: 9.33s\tremaining: 11.4s\n",
            "45:\tlearn: 0.6753056\ttotal: 9.47s\tremaining: 11.1s\n",
            "46:\tlearn: 0.6743231\ttotal: 9.61s\tremaining: 10.8s\n",
            "47:\tlearn: 0.6738056\ttotal: 9.74s\tremaining: 10.6s\n",
            "48:\tlearn: 0.6733833\ttotal: 9.88s\tremaining: 10.3s\n",
            "49:\tlearn: 0.6727811\ttotal: 10s\tremaining: 10s\n",
            "50:\tlearn: 0.6723125\ttotal: 10.1s\tremaining: 9.74s\n",
            "51:\tlearn: 0.6718695\ttotal: 10.3s\tremaining: 9.48s\n",
            "52:\tlearn: 0.6714259\ttotal: 10.4s\tremaining: 9.24s\n",
            "53:\tlearn: 0.6709388\ttotal: 10.6s\tremaining: 8.99s\n",
            "54:\tlearn: 0.6707110\ttotal: 10.7s\tremaining: 8.74s\n",
            "55:\tlearn: 0.6703604\ttotal: 10.8s\tremaining: 8.5s\n",
            "56:\tlearn: 0.6698996\ttotal: 10.9s\tremaining: 8.26s\n",
            "57:\tlearn: 0.6694087\ttotal: 11.1s\tremaining: 8.02s\n",
            "58:\tlearn: 0.6690902\ttotal: 11.2s\tremaining: 7.79s\n",
            "59:\tlearn: 0.6684149\ttotal: 11.3s\tremaining: 7.56s\n",
            "60:\tlearn: 0.6680523\ttotal: 11.5s\tremaining: 7.34s\n",
            "61:\tlearn: 0.6678006\ttotal: 11.6s\tremaining: 7.12s\n",
            "62:\tlearn: 0.6675139\ttotal: 11.8s\tremaining: 6.9s\n",
            "63:\tlearn: 0.6672523\ttotal: 11.9s\tremaining: 6.69s\n",
            "64:\tlearn: 0.6669996\ttotal: 12s\tremaining: 6.47s\n",
            "65:\tlearn: 0.6666879\ttotal: 12.1s\tremaining: 6.26s\n",
            "66:\tlearn: 0.6663151\ttotal: 12.3s\tremaining: 6.05s\n",
            "67:\tlearn: 0.6657474\ttotal: 12.4s\tremaining: 5.84s\n",
            "68:\tlearn: 0.6655494\ttotal: 12.6s\tremaining: 5.64s\n",
            "69:\tlearn: 0.6652981\ttotal: 12.7s\tremaining: 5.43s\n",
            "70:\tlearn: 0.6651045\ttotal: 12.8s\tremaining: 5.24s\n",
            "71:\tlearn: 0.6649578\ttotal: 13s\tremaining: 5.07s\n",
            "72:\tlearn: 0.6647938\ttotal: 13.3s\tremaining: 4.91s\n",
            "73:\tlearn: 0.6644775\ttotal: 13.5s\tremaining: 4.75s\n",
            "74:\tlearn: 0.6641733\ttotal: 13.8s\tremaining: 4.59s\n",
            "75:\tlearn: 0.6639172\ttotal: 13.9s\tremaining: 4.4s\n",
            "76:\tlearn: 0.6636743\ttotal: 14.2s\tremaining: 4.24s\n",
            "77:\tlearn: 0.6631019\ttotal: 14.4s\tremaining: 4.07s\n",
            "78:\tlearn: 0.6626995\ttotal: 14.7s\tremaining: 3.9s\n",
            "79:\tlearn: 0.6623059\ttotal: 14.9s\tremaining: 3.73s\n",
            "80:\tlearn: 0.6618600\ttotal: 15.2s\tremaining: 3.56s\n",
            "81:\tlearn: 0.6616589\ttotal: 15.4s\tremaining: 3.38s\n",
            "82:\tlearn: 0.6612313\ttotal: 15.6s\tremaining: 3.2s\n",
            "83:\tlearn: 0.6610992\ttotal: 15.9s\tremaining: 3.03s\n",
            "84:\tlearn: 0.6608711\ttotal: 16.1s\tremaining: 2.85s\n",
            "85:\tlearn: 0.6604941\ttotal: 16.4s\tremaining: 2.66s\n",
            "86:\tlearn: 0.6601741\ttotal: 16.6s\tremaining: 2.48s\n",
            "87:\tlearn: 0.6600863\ttotal: 16.9s\tremaining: 2.3s\n",
            "88:\tlearn: 0.6599776\ttotal: 17.1s\tremaining: 2.11s\n",
            "89:\tlearn: 0.6598489\ttotal: 17.3s\tremaining: 1.92s\n",
            "90:\tlearn: 0.6594617\ttotal: 17.6s\tremaining: 1.74s\n",
            "91:\tlearn: 0.6593825\ttotal: 17.8s\tremaining: 1.55s\n",
            "92:\tlearn: 0.6590596\ttotal: 18.1s\tremaining: 1.36s\n",
            "93:\tlearn: 0.6589786\ttotal: 18.3s\tremaining: 1.17s\n",
            "94:\tlearn: 0.6587871\ttotal: 18.5s\tremaining: 976ms\n",
            "95:\tlearn: 0.6585648\ttotal: 18.8s\tremaining: 783ms\n",
            "96:\tlearn: 0.6583310\ttotal: 19s\tremaining: 587ms\n",
            "97:\tlearn: 0.6577974\ttotal: 19.1s\tremaining: 390ms\n",
            "98:\tlearn: 0.6576869\ttotal: 19.2s\tremaining: 194ms\n",
            "99:\tlearn: 0.6573217\ttotal: 19.4s\tremaining: 0us\n",
            "Accuracy: 0.72\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.01      0.03      1578\n",
            "           1       0.62      0.69      0.66      5025\n",
            "           2       0.79      0.89      0.83      7642\n",
            "\n",
            "    accuracy                           0.72     14245\n",
            "   macro avg       0.62      0.53      0.51     14245\n",
            "weighted avg       0.69      0.72      0.68     14245\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Output predicted values of test data and print accuracy\n",
        "\n",
        "# Save the 'enc_id' column to create the submission DataFrame\n",
        "enc_id = test_data['enc_id'].values  # Convert to a simple array\n",
        "\n",
        "test_x = test_data.drop(columns=columns_to_drop, axis=1)\n",
        "test_x = test_x.apply(lambda x: x.fillna(x.mode().iloc[0]))\n",
        "\n",
        "for column in categorical_columns:\n",
        "    test_x[column] = label_encoder.fit_transform(test_x[column])\n",
        "\n",
        "test_x = test_x[X.columns]\n",
        "\n",
        "# Make predictions on the test data\n",
        "catboost_predictions = catboost_classifier.predict(test_x)\n",
        "\n",
        "# Convert to simple arrays\n",
        "enc_id = enc_id.flatten()\n",
        "catboost_predictions = catboost_predictions.flatten()\n",
        "\n",
        "# Check lengths\n",
        "if len(enc_id) != len(catboost_predictions):\n",
        "    raise ValueError(\"Length mismatch between 'enc_id' and 'catboost_predictions'.\")\n",
        "\n",
        "# Create a DataFrame with 'enc_id' and 'predicted readmission_id' for CatBoost\n",
        "catboost_result_df = pd.DataFrame({'enc_id': enc_id, 'predicted_readmission_id': catboost_predictions})\n",
        "\n",
        "# Save the CatBoost result to a CSV file\n",
        "catboost_result_df.to_csv('catboost_predictions.csv', index=False)"
      ],
      "metadata": {
        "id": "vp9iMJyaZiI2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightgbm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpkeU9fpXKnz",
        "outputId": "c6bc4ec3-fce9-42ac-a19b-34c035a009da"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.11.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "# Define your features (X) and target (y)\n",
        "X = train_data.drop(columns=['readmission_id'])\n",
        "y = train_data['readmission_id']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a LightGBM classifier\n",
        "lgb_classifier = LGBMClassifier(num_iterations=100, max_depth=6, learning_rate=0.1, random_seed=42)\n",
        "\n",
        "# Train the LightGBM model on the training data\n",
        "lgb_classifier.fit(X_train, y_train, categorical_feature=categorical_columns)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = lgb_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "\n",
        "# Generate a classification report to see precision, recall, F1-score, etc.\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnGRM3ryXUo2",
        "outputId": "fbba6869-a5f5-4035-c598-951752675329"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:172: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041350 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2123\n",
            "[LightGBM] [Info] Number of data points in the train set: 56980, number of used features: 22\n",
            "[LightGBM] [Info] Start training from score -2.191101\n",
            "[LightGBM] [Info] Start training from score -1.054194\n",
            "[LightGBM] [Info] Start training from score -0.616680\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "Accuracy: 0.72\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.08      0.13      1578\n",
            "           1       0.64      0.66      0.65      5025\n",
            "           2       0.78      0.90      0.84      7642\n",
            "\n",
            "    accuracy                           0.72     14245\n",
            "   macro avg       0.61      0.55      0.54     14245\n",
            "weighted avg       0.69      0.72      0.69     14245\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Output predicted values of test data and print accuracy\n",
        "\n",
        "# Save the 'enc_id' column to create the submission DataFrame\n",
        "enc_id = test_data['enc_id']\n",
        "\n",
        "test_x = test_data.drop(columns=columns_to_drop, axis=1)\n",
        "test_x = test_x.apply(lambda x: x.fillna(x.mode().iloc[0]))\n",
        "\n",
        "for column in categorical_columns:\n",
        "    test_x[column] = label_encoder.fit_transform(test_x[column])\n",
        "\n",
        "test_x = test_x[X.columns]\n",
        "\n",
        "# Make predictions on the test data\n",
        "lgb_predictions = lgb_classifier.predict(test_x)\n",
        "\n",
        "# Create a DataFrame with 'enc_id' and 'predicted readmission_id' for LightGBM\n",
        "lgb_result_df = pd.DataFrame({'enc_id': enc_id, 'predicted_readmission_id': lgb_predictions})\n",
        "\n",
        "# Save the LightGBM result to a CSV file\n",
        "lgb_result_df.to_csv('lgb_predictions.csv', index=False)\n",
        "\n",
        "################################################################################################################\n",
        "# test_predictions = best_model.predict(test_x)\n",
        "# result_df = pd.DataFrame({'enc_id': test_data['enc_id'], 'predicted_readmission_id': test_predictions})\n",
        "\n",
        "# result_df.to_csv('predicted_results.csv', index=False)\n",
        "\n",
        "# val_predictions = best_model.predict(X_test)\n",
        "# accuracy = accuracy_score(y_test, val_predictions)\n",
        "# print(f'Accuracy on the validation set: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_O16UCoxX_tu",
        "outputId": "0eee3e77-11c2-46ba-ee2d-01e82158fbfa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}